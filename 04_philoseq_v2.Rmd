---
title: "Philoseq"
output: 
  github_document:
    toc: true
    toc_depth: 3
---
# Préparation du script
## Lecture de l'environnement de Dada2
```{r}
load("03_DADA2_tutorial_FinalEnv")
```

## Chargement des librairies
```{r}
library(phyloseq)
library(Biostrings)
library(ggplot2)
theme_set(theme_bw())
```
## récupération des données du tutoriel
```{r}
ps_connect <-url("https://raw.githubusercontent.com/spholmes/F1000_workflow/master/data/ps.rds")
ps = readRDS(ps_connect)
ps
```
# Taxonomic Filtering
 Ces lignes de codes nous permettent de compter le nombre d'echantillons qu'on a pour chaque phylums.
```{r}
# Show available ranks in the dataset
rank_names(ps)
```
Sur la table affichée, nous pouvons compter 6 échantillons qui n'ont pas de phyla defini. Cela peut etre dû à une mauvaise filtration : ce serait des artefacts.
```{r}
# Create table, number of features for each phyla
table(tax_table(ps)[, "Phylum"], exclude = NULL)
```
 Ce code nous permet de nous assurer ques les séquences pour lesquelles les anotations sont ambigues vont bien être retirées.
```{r}
ps <- subset_taxa(ps, !is.na(Phylum) & !Phylum %in% c("", "uncharacterized"))
```
Ici nous allons mesurer la prévalence, qui sera dans le cadre de cette étude le nombre d'echantillons par taxon (avec au minimum un echantillon par taxon du coup)
```{r}
# Compute prevalence of each feature, store as data.frame
prevdf = apply(X = otu_table(ps),
               MARGIN = ifelse(taxa_are_rows(ps), yes = 1, no = 2),
               FUN = function(x){sum(x > 0)})
# Add taxonomy and total read counts to this data.frame
prevdf = data.frame(Prevalence = prevdf,
                    TotalAbundance = taxa_sums(ps),
                    tax_table(ps))
```
Cette commande nous permet d'evaluer la prévalence moyenne de chaque phylum (colonne1) et la prévalence totale (colonne2). Les résultats de cette commande nous montre que Fusobacteria est trouvée seulement 2 fois. idem pour deinococcus-thermus qui n'est retrouvé que dans un seul échantillon (même si au sein de cet echantillon nous l'y retrouvons 52 fois).Nous allons donc le retirer car il risque de nous gêner.
```{r}
plyr::ddply(prevdf, "Phylum", function(df1){cbind(mean(df1$Prevalence),sum(df1$Prevalence))})
```

```{r}
# Define phyla to filter
filterPhyla = c("Fusobacteria", "Deinococcus-Thermus")
# Filter entries with unidentified Phylum.
ps1 = subset_taxa(ps, !Phylum %in% filterPhyla)
ps1
```
#Prevalence Filtering
 Ces manipulations nous permettent de voir si nous avons manqué de voir des echantillons mal definis ou en tres faible quantité qui devraient etre retirés. On va aussi pouvoir avoir un aperçu des séquences qui sont rangées dans chaque features. 
Ici; chaque point représente un taxa. Nous ne voyons pas de seuil de prévalence clairement établi ici. Nous avons donc des taxons assez stables. Néanmoins nous pouvons fixer manuelle le seuil de prévalence quelque part entre 0 et 10% (en verifiant qu'il n'y a pas d'impact non attendu sur la suite de l'étude)
```{r}
# Subset to the remaining phyla
prevdf1 = subset(prevdf, Phylum %in% get_taxa_unique(ps1, "Phylum"))
ggplot(prevdf1, aes(TotalAbundance, Prevalence / nsamples(ps),color=Phylum)) +
  # Include a guess for parameter
  geom_hline(yintercept = 0.05, alpha = 0.5, linetype = 2) +  geom_point(size = 2, alpha = 0.7) +
  scale_x_log10() +  xlab("Total Abundance") + ylab("Prevalence [Frac. Samples]") +
  facet_wrap(~Phylum) + theme(legend.position="none")
```
on va donc fixer un seuil de prévalence de 5%, c'est-à- dire que nous allons retirer toutes les valeurs de prévalence inferieures à 95%.
```{r}
# Define prevalence threshold as 5% of total samples
prevalenceThreshold = 0.05 * nsamples(ps)
prevalenceThreshold
```
C'est grâce à la fonction prune_taxa qu'on va pouvoir retirer les ASVs qui ne respectent pas le seuil de prévalence
```{r}
# Execute prevalence filter, using `prune_taxa()` function
keepTaxa = rownames(prevdf1)[(prevdf1$Prevalence >= prevalenceThreshold)]
ps2 = prune_taxa(keepTaxa, ps)
```

# Agglomerate taxa
on sait que les communautés microbiennes sont souvent composées de taxons qui partagent des caractéristiques communes. On va donc chercher à mettre ensemble les taxons qui sont très proches les uns de autres.
Pour cela, l'aggregation taxonomique est pratique. Elle est facile, et on peut comparer les taxons grâce à des arbres simples à rangs. Pour le generer on va pouvoir utiliser phyloseq. La première chose qui sera faite sera d'agglomerer ensemble les échantillons du même genre. 
```{r}
# How many genera would be present after filtering?
length(get_taxa_unique(ps2, taxonomic.rank = "Genus"))
```
tax_glom est une fonction qui permet de rassembler les espèces ayant une taxonomie proche. On va donc mettre ces séquences là dans l'objet "ps3" qui va nous servir pour la construction de l'arbre.
```{r}
ps3 = tax_glom(ps2, "Genus", NArm = TRUE)
```
Tip_glom est une fonction analogue à tax_glom. Il nous permet de séparer les distances cophenetiques inférieures à une valeur h. La distance cophenetique est la distance entre deux objets dans l'arbre dont les branches comprennent deux objets réduits en une branche. On va donc créer un objet ps4 qui portera cette caractéristique. 
```{r}
h1 = 0.4
ps4 = tip_glom(ps2, h = h1)
```
ici phyloseq va comparer les datas originales par rapport à l'arbre obtenu après agglomeration taxonomiques et enfin à l'arbre après les agglomerations phylogéniques. Grâce à la fonction gridExtra, nous pourrons ainsi générer ces 3 objets en un.
```{r}
multiPlotTitleTextSize = 15
p2tree = plot_tree(ps2, method = "treeonly",
                   ladderize = "left",
                   title = "Before Agglomeration") +
  theme(plot.title = element_text(size = multiPlotTitleTextSize))
p3tree = plot_tree(ps3, method = "treeonly",
                   ladderize = "left", title = "By Genus") +
  theme(plot.title = element_text(size = multiPlotTitleTextSize))
p4tree = plot_tree(ps4, method = "treeonly",
                   ladderize = "left", title = "By Height") +
  theme(plot.title = element_text(size = multiPlotTitleTextSize))
library (gridExtra)
gridExtra::grid.arrange
```
Sur la gauche nous retrouvons l'arbre original, au milieu l'arbre généré par agglomération taxonomique et à droit l'arbre généré par aggrégation phylogénique. On peut voir que les deux agglomérations nous permettent de clarifier les arbres. De plus, les arbres obtenus avec les deux types d'agglomération sont assez ressemblant.
```{r}
# group plots together
grid.arrange(nrow = 1, p2tree, p3tree, p4tree)
```
# Abundance value transformation
on peut avoir besoin de transformer nos données pour pouvoir calculer des variances. 
On va d'abord utiliser la fonction "plot_abundance" pour definir un graphique d'abondance relative. Cela va nous permettre de comparer facilement les différentes échelles et les distributions d'abondance avant de les transformer.
```{r}
plot_abundance = function(physeq,title = "",
                          Facet = "Order", Color = "Phylum"){
  # Arbitrary subset, based on Phylum, for plotting
  p1f = subset_taxa(physeq, Phylum %in% c("Firmicutes"))
  mphyseq = psmelt(p1f)
  mphyseq <- subset(mphyseq, Abundance > 0)
  ggplot(data = mphyseq, mapping = aes_string(x = "sex",y = "Abundance",
                              color = Color, fill = Color)) +
    geom_violin(fill = NA) +
    geom_point(size = 1, alpha = 0.3,
               position = position_jitter(width = 0.3)) +
    facet_wrap(facets = Facet) + scale_y_log10()+
    theme(legend.position="none")
}
```
la fonction "transform_sample_counts" pour transformer les dénombrements en leur fréquence par rapport à leurs abondances relatives.
```{r}
# Transform to relative abundance. Save as new object.
ps3ra = transform_sample_counts(ps3, function(x){x / sum(x)})
```
On va donc pouvoir tracer le graphique des valeurs d'abondances avant et après transformation. On peut voir qu'après les transformations, les valeurs d'abondances relatives sont mieux réparties et permettent une lecture plus aisées des différents paramètres. 
```{r}
plotBefore = plot_abundance(ps3,"")
plotAfter = plot_abundance(ps3ra,"")
# Combine each plot into one graphic.
grid.arrange(nrow = 1,  plotBefore, plotAfter)
```
# Subset by taxonomy
On remarque que les Lactobacillales apparaissent comme une distribution taxonomique bimodale. On va donc chercher à examiner les taxons du genre Lactobacillales pour expliquer cette répartition bimodale. Pour cela nous allons préciser le taxon dont nous voulons avoir le graphique.
Lorsqu'on regarde les graphiques, on remarque les abondances relatives en fonction du sexe de l'hote sur lequelle les bactéries ont été prélevées.Ici il apparait donc clairement que la répartition bimodale de Lactobacillales provient Streptococcus (moins abondant) et de Lactobacillus qui a une abondance relative très élevée.
```{r}
psOrd = subset_taxa(ps3ra, Order == "Lactobacillales")
plot_abundance(psOrd, Facet = "Genus", Color = NULL)
```
# Preprocessing
Nous allons ensuite vouloir analyser les données en utilisant des projections multivariées. La fonction ci-dessous va s'interesser à l'âge des souris sur lesquelles ont été prélevées les bactéries. Les souris vont donc être +/- agées. Nous allons compter le nombre d'echantillons pour chaque catégorie d'âge. ces comptages vont être convertis en logarithmes, ce qui va permettre de stabiliser la variance. On peut ainsi visualiser que l'âge permet de répartir les échantillons entre 3 clusters séparés, ce qui incite à construire une autre variable qui prenne en compte cela.

```{r}
qplot(sample_data(ps)$age, geom = "histogram",binwidth=20) + xlab("age")
```
Ici nous allons comparer les données brutes avec les données logarithmiques. Au vu des résultats, on peut interpreter que les variances sont suffisamment normalisées avec "log(1+x)" pour pouvoir explorer les abondances relatives.
En réalité, pour d'autres analyses, cela ne sera pas suffisant. On recommande de plutot utiliser la fonction phyloseq_to_deseq2. 

```{r}
qplot(log10(rowSums(otu_table(ps))),binwidth=0.2) +
  xlab("Logged counts-per-sample")
```
# Première PcoA
ce code nous permets de tracer une PcoA grâce à l'indice de dissimilarité de Bray-Curtis. On remarque que quelques échantillons sont à part. Ils correspondent d'après les auteurs aux femelles 5 et 6 du jour 165 et aux mâles 3,4,5 et 6 du jour 175. Nous pouvons voir le nom de ces échantillons en rejoutant label= "SampleID" dans l'objet "out.wuf.log", juste après "distance = "wunifrac"". Par soucis de clarté dans cette figure, j'ai décidé de ne pas le laisser.  Nous allons explorer la relation entre ces échantillons précis afin de pouvoir analyser ce qui les lient ensembles.
```{r}
sample_data(ps)$age_binned <- cut(sample_data(ps)$age,
                          breaks = c(0, 100, 200, 400))
levels(sample_data(ps)$age_binned) <- list(Young100="(0,100]", Mid100to200="(100,200]", Old200="(200,400]")
sample_data(ps)$family_relationship=gsub(" ","",sample_data(ps)$family_relationship)
pslog <- transform_sample_counts(ps, function(x) log(1 + x))
out.wuf.log <- ordinate(pslog, method = "MDS", distance = "wunifrac")
evals <- out.wuf.log$values$Eigenvalues
plot_ordination(pslog, out.wuf.log, color = "age_binned") +
  labs(col = "Binned Age") +
  coord_fixed(sqrt(evals[2] / evals[1]))
```
Avec ce code, nous cherchons à analyser les deux femelles préalablement citées.Elles contiennent un même ASV qui qui a une forte abondance relative (90%). C'est la première fois qu'il y a une telle abondance car le reste du temps il a une abondance inférieure à 20%. De plus, sa diversité est la plus basse parmis tous les échantillons.
```{r}
rel_abund <- t(apply(otu_table(ps), 1, function(x) x / sum(x)))
qplot(rel_abund[, 12], geom = "histogram",binwidth=0.05) +
  xlab("Relative abundance")
```
# Different Ordination Projections
On va chercher à avoir des matrices de distance et différentes méthodes d'ordination qui vont nous permettre d'analyser les données. Nous allons donc retirer les "outliers" dans un premier temps, soit les échantillons qui avaient une dissimilarité forte par rapport au reste des échantillons.
```{r}
outliers <- c("F5D165", "F6D165", "M3D175", "M4D175", "M5D175", "M6D175")
ps <- prune_samples(!(sample_names(ps) %in% outliers), ps)
```
De plus, nous retirons les échantillons qui contiennent moins de 1000 reads.
```{r}
which(!rowSums(otu_table(ps)) > 1000)
```

```{r}
ps <- prune_samples(rowSums(otu_table(ps)) > 1000, ps)
pslog <- transform_sample_counts(ps, function(x) log(1 + x))
```

# Autres PcoA
Nous allons demander à la machine de nous calculer une analyse par PcoA en utilisant l'indice de dissimilarité de Bray-Curtis. En regardant la figure obetnue, on peut clairement voir que l'age influence les communautés microbiennes retrouvées, avec une séparation vraiment nette entre les ASV des souris jeune et les souris d'âge moyen. Les souris plus agées semblent être retrouvées groupées avec les ASVs des souris moyennement agées. Si nous observons le second axe, nous pouvons trouver que les échantillons avec un plus grand score, ce qui correspond aux échantillons des souris moyennement agées et plus agées, sont les échantillons avec beaucoup de taxon appartenant aux Bacteroidetes avec un sous groupe de Firmicutes.
```{r}
out.pcoa.log <- ordinate(pslog,  method = "MDS", distance = "bray")
evals <- out.pcoa.log$values[,1]
plot_ordination(pslog, out.pcoa.log, color = "age_binned",
                  shape = "family_relationship") +
  labs(col = "Binned Age", shape = "Litter")+
  coord_fixed(sqrt(evals[2] / evals[1]))
```
#double principal coordinates analysis (DPCoA)
Cette PcoA est clairement dominée par l'axe 1, qui exprime 75% de variabilité, contre 8,5 sur l'Axe2. Cela est obtenu dû à l'ajout des informations phylogénétiques pour pouvoir générer cette PcoA.
```{r}
out.dpcoa.log <- ordinate(pslog, method = "DPCoA")
evals <- out.dpcoa.log$eig
plot_ordination(pslog, out.dpcoa.log, color = "age_binned", label= "SampleID",
                  shape = "family_relationship") +
  labs(col = "Binned Age", shape = "Litter")+
  coord_fixed(sqrt(evals[2] / evals[1]))
```
Nous allons donc chercher quel taxa est responsable de la PcoA juste au dessus. Pour cela nous allons faire un DPcoA, qui utilise l'abondance et les informations phylogénétiques contenues dans la classe phyloseq. L'objet final représente la distance patristique (somme des longueurs des branches qui joignent deux points) et cophenetique développée plus haut. Dans cette DPcoA, nous pouvons revoir que l'âge a un effet dans cette répartition. On peut y voir que quasiment tous les phylums représentés sur cette DPcoA sont ensembles, mis à part les Bactéroidetes qui sont assez dissimilaires au reste.  
```{r}
plot_ordination(pslog, out.dpcoa.log, type = "species", color = "Phylum") +
  coord_fixed(sqrt(evals[2] / evals[1]))
```

Lorsqu'on reproduit la PCoA dominée par l'Axe 1 en utilisant unifrac comme indice de distance Unifrac, nous obtenons une PcoA beaucoup plus lisible.
Grâce à ces exemples, on peut se rendre compte qu'il est important d'adapter sa technique de projection par rapport aux datas afin de mieux les visualiser.
```{r}
out.wuf.log <- ordinate(pslog, method = "PCoA", distance ="wunifrac")
evals <- out.wuf.log$values$Eigenvalues
plot_ordination(pslog, out.wuf.log, color = "age_binned",
                  shape = "family_relationship") +
  coord_fixed(sqrt(evals[2] / evals[1])) +
  labs(col = "Binned Age", shape = "Litter")
```
#PCA on ranks
Création d'une matrice représentant l'abondance par son range, avec la bactérie la moins présente est mise au rang 1, puis la seconde moins présente est mise au rang 2, etc.
```{r}
abund <- otu_table(pslog)
abund_ranks <- t(apply(abund, 1, rank))
```
Il faut faire attention car ces rangs peut renforcer les différences entre les rangs des taxons les plus représentés et les moins représentés. Pour éviter cela, toutes les bactéries qui seront sous la valeur seuil d'abondance seront mise à une valeur d'abondance de 1. Les rangs des autres bactéries seront alors décalées vers le bas afin d'eviter les gros écarts de rang. 
```{r}
abund_ranks <- abund_ranks - 329
abund_ranks[abund_ranks < 1] <- 1
```

```{r}
library(dplyr)
library(reshape2)
abund_df <- melt(abund, value.name = "abund") %>%
  left_join(melt(abund_ranks, value.name = "rank"))
colnames(abund_df) <- c("sample", "seq", "abund", "rank")

abund_df <- melt(abund, value.name = "abund") %>%
  left_join(melt(abund_ranks, value.name = "rank"))
colnames(abund_df) <- c("sample", "seq", "abund", "rank")

sample_ix <- sample(1:nrow(abund_df), 8)
ggplot(abund_df %>%
         filter(sample %in% abund_df$sample[sample_ix])) +
  geom_point(aes(x = abund, y = rank, col = sample),
             position = position_jitter(width = 0.2), size = 1.5) +
  labs(x = "Abundance", y = "Thresholded rank") +
  scale_color_brewer(palette = "Set2")
```

Nous avons pu ordonner en rangs nos différentes abondances, nous allons ainsi pouvoir maintenant faire une PcoA grâce au code ci dessous.Nous retrouvons une dispersion similaire à celles trouvées dans les autres PcoA, ce qui nous permet d'être plutôt sûrs que ces données sont bien dûes aux séquences elles-mêmes qui sont donc fiables, qu'à notre moyen de projection qui pourrait influencer les interpretations de manière différente selon la projection choisie. Cela serait signe de mauvaises données car nous obtiendrions des résultats différents pour les mêmes séquences, ce qui n'est pas souhaitable.
```{r}
library(ade4)
ranks_pca <- dudi.pca(abund_ranks, scannf = F, nf = 3)
row_scores <- data.frame(li = ranks_pca$li,
                         SampleID = rownames(abund_ranks))
col_scores <- data.frame(co = ranks_pca$co,
                         seq = colnames(abund_ranks))
tax <- tax_table(ps) %>%
  data.frame(stringsAsFactors = FALSE)
tax$seq <- rownames(tax)
main_orders <- c("Clostridiales", "Bacteroidales", "Lactobacillales",
                 "Coriobacteriales")
tax$Order[!(tax$Order %in% main_orders)] <- "Other"
tax$Order <- factor(tax$Order, levels = c(main_orders, "Other"))
tax$otu_id <- seq_len(ncol(otu_table(ps)))
row_scores <- row_scores %>%
  left_join(sample_data(pslog))
col_scores <- col_scores %>%
  left_join(tax)
evals_prop <- 100 * (ranks_pca$eig / sum(ranks_pca$eig))
ggplot() +
  geom_point(data = row_scores, aes(x = li.Axis1, y = li.Axis2), shape = 2) +
  geom_point(data = col_scores, aes(x = 25 * co.Comp1, y = 25 * co.Comp2, col = Order),
             size = .3, alpha = 0.6) +
  scale_color_brewer(palette = "Set2") +
  facet_grid(~ age_binned) +
  guides(col = guide_legend(override.aes = list(size = 3))) +
  labs(x = sprintf("Axis1 [%s%% variance]", round(evals_prop[1], 2)),
       y = sprintf("Axis2 [%s%% variance]", round(evals_prop[2], 2))) +
  coord_fixed(sqrt(10*ranks_pca$eig[2] / ranks_pca$eig[1])) +
  theme(panel.border = element_rect(color = "#787878", fill = alpha("white", 0)))
```
# Canonical correspondence
Les Canonical Correspondence Analysis (CCpnA) sont des ordinations en utilisant des tables d'echantillonage qui permettent d'incorporer des informations supplémentaires, comme l'age, les liens de parenté entre les souris, etc.
Les positions des échantillons sont déterminés par similarité dans les signatures d'espèce et des caractéristiques environnementales.

Le premier code spécifie un "extra-argument" qui permet de préciser les paramètres à utiliser pour faire l'ordination.
```{r}
ps_ccpna <- ordinate(pslog, "CCA", formula = pslog ~ age_binned + family_relationship)
```
ici nous décidons de joindre les différents scores avec les données environnementales. Parmis les 23 différents taxons, on décide d'annoter seulement les 4 les plus abondants qui permet de rendre le graphique plus lisible. 
```{r}
library(ggrepel)
ps_scores <- vegan::scores(ps_ccpna)
sites <- data.frame(ps_scores$sites)
sites$SampleID <- rownames(sites)
sites <- sites %>%
  left_join(sample_data(ps))

species <- data.frame(ps_scores$species)
species$otu_id <- seq_along(colnames(otu_table(ps)))
species <- species %>%
  left_join(tax)
evals_prop <- 100 * ps_ccpna$CCA$eig[1:2] / sum(ps_ccpna$CA$eig)
ggplot() +
  geom_point(data = sites, aes(x = CCA1, y = CCA2), shape = 2, alpha = 0.5) +
  geom_point(data = species, aes(x = CCA1, y = CCA2, col = Order), size = 0.5) +
  geom_text_repel(data = species %>% filter(CCA2 < -2),
                    aes(x = CCA1, y = CCA2, label = otu_id),
            size = 1.5, segment.size = 0.1) +
  facet_grid(. ~ family_relationship) +
  guides(col = guide_legend(override.aes = list(size = 3))) +
  labs(x = sprintf("Axis1 [%s%% variance]", round(evals_prop[1], 2)),
        y = sprintf("Axis2 [%s%% variance]", round(evals_prop[2], 2))) +
  scale_color_brewer(palette = "Set2") +
  coord_fixed(sqrt(ps_ccpna$CCA$eig[2] / ps_ccpna$CCA$eig[1])*0.45   ) +
  theme(panel.border = element_rect(color = "#787878", fill = alpha("white", 0)))

```

#Supervised learning
L'apprentissage surpervisé des machines consiste à utiliser des algorithmes de R qui vont pouvoir choisir des paramètres de manière automatique. Nous avons vu avec les analyses précedantes que l'âge des souris influençait les communautés. Ici, grâce aux techniques d'apprentissage supervisé, nous allons essayer de prédire l'âge des souris par rapport aux communautés microbiennes retrouvées. 
La première étape pour pouvoir faire cela sera donc de diviser les données en différents sets de tests avec les assignements donnés par souris (et non par echantillon) pour s'assurer que les différents tests simulent bien une collection de  nouvelles données.Nous allons suivre le modèle "Partial Least Squares" (PLS). Une fois ces données divisées, nous pouvons utiliser la fonction "train" pour coller le plus possible à notre modèle.
Ici nous commençons par charger notre librairie pour éviter les messages d'erreur.
```{r}
library (lattice)
```
Créations des différents objets qui vont nous servir pour appliquer la méthode d'apprentissage supervisé.
```{r}
library(caret)
sample_data(pslog)$age2 <- cut(sample_data(pslog)$age, c(0, 100, 400))
dataMatrix <- data.frame(age = sample_data(pslog)$age2, otu_table(pslog))
# take 8 mice at random to be the training set, and the remaining 4 the test set
trainingMice <- sample(unique(sample_data(pslog)$host_subject_id), size = 3)
inTrain <- which(sample_data(pslog)$host_subject_id %in% trainingMice)
training <- dataMatrix[inTrain,]
testing <- dataMatrix[-inTrain,]
plsFit <- train(age ~ ., data = training,
                method = "pls", preProc = "center")
```
Ici nous utilisons la fonction "predict" dont nous allons comparer les résultats par rapport aux vraies données. On peut voir qu'il y a eu un peu d'erreur, et lorsqu'on rejoue les codes ci dessus et qu'on refait une simulation, on a de moins en moins d'erreurs. On peut donc voir que cette méthode est plutôt efficace. On remarque aussi que lorsqu'on réduit le nombre de souris par test, la méthode devient de plus en plus fine, faisant moins d'erreurs comparé au nombre d'echantillon.
```{r}
plsClasses <- predict(plsFit, newdata = testing)
table(plsClasses, testing$age)
```
Ici nous allons quitter le modèle PLS pour appliquer le modèle random forests. Il utilise le même principe que PLS en switchant les données. J'ai rajouté une nouvelle demande de library pour ggplot2 afin d'éviter d'avoir des objets cachés. Au vu des résultats, on peut voir que c'est un modèle efficace, néanmoins il faut noter que quelques souris agées qui se sont retrouvées parmis les souris jeunes, avec un taux d'erreur legerement supérieur à celui de PLS.
```{r}
library(randomForest)
library (ggplot2)
rfFit <- train(age ~ ., data = training, method = "rf",
               preProc = "center", proximity = TRUE)
rfClasses <- predict(rfFit, newdata = testing)
table(rfClasses, testing$age)
```
Pour pouvoir interpreter les résultats des deux modèles différents, nous allons génerer un biplot standard (pour PLS) et un graphique de proximité (random forests). Ce dernier consiste à utiliser des scores de proximité qui évalue une répartition dans l'espace. Le code ci-dessous nous permet, après avoir chargé la librairie "vegan", d'extraire les coordonnées et les annotations supplémentaires pour chaque points incluant le biplot PLS.
```{r}
library(permute)
library (vegan)
```
Nous pouvons, sur le graphique obtenu, interpreter les résultats de la même façon que dans les précédantes ordinations, mais la projection choisie permet de mettre en évidence explicitement les variables d'âge regroupées. De plus, grâce à cette projection, nous pouvons identifier un espace qui va nous permettre de maximiser les discriminations selon les classes. Ainsi, nous pouvons utiliser des projections et des coefficients d'ASV qui permettent de respecter cet espace spécifique. 
```{r}
pls_biplot <- list("loadings" = loadings(plsFit$finalModel),
                   "scores" = scores(plsFit$finalModel))
class(pls_biplot$scores) <- "matrix"

pls_biplot$scores <- data.frame(sample_data(pslog)[inTrain, ],
                                pls_biplot$scores)

tax <- tax_table(ps)@.Data %>%
  data.frame(stringsAsFactors = FALSE)
main_orders <- c("Clostridiales", "Bacteroidales", "Lactobacillales",
                 "Coriobacteriales")
tax$Order[!(tax$Order %in% main_orders)] <- "Other"
tax$Order <- factor(tax$Order, levels = c(main_orders, "Other"))
class(pls_biplot$loadings) <- "matrix"
pls_biplot$loadings <- data.frame(tax, pls_biplot$loadings)
ggplot() +
  geom_point(data = pls_biplot$scores,
             aes(x = Comp.1, y = Comp.2), shape = 2) +
  geom_point(data = pls_biplot$loadings,
             aes(x = 25 * Comp.1, y = 25 * Comp.2, col = Order),
             size = 0.3, alpha = 0.6) +
  scale_color_brewer(palette = "Set2") +
  labs(x = "Axis1", y = "Axis2", col = "Binned Age") +
  guides(col = guide_legend(override.aes = list(size = 3))) +
  facet_grid( ~ age2) +
  theme(panel.border = element_rect(color = "#787878", fill = alpha("white", 0)))
```
Ici nous allons donc génerer le graphique de proximité pour analyser les données de random forests. Nous calculons ici les distances entre les échantillons par rapport au nombre de fois où elle apparait dans le bootstrapping performé par random forests. Ainsi si on a une paire d'échantillons qui apparaissent souvent avec la même partition, alors cette paire aura une distance faible entre elle. Les distances finales sont placées dans une PCoA. Les séparations sont donc claires, et peuvent être comparées manuellement en observant les différents points. On peut donc se rendre compte selon le point qu'on aura des échantillons +/- faciles à classifier.
```{r}
rf_prox <- cmdscale(1 - rfFit$finalModel$proximity) %>%
  data.frame(sample_data(pslog)[inTrain, ])

ggplot(rf_prox) +
  geom_point(aes(x = X1, y = X2, col = age_binned),
             size = 1, alpha = 0.7) +
  scale_color_manual(values = c("#A66EB8", "#238DB5", "#748B4F")) +
  guides(col = guide_legend(override.aes = list(size = 4))) +
  labs(col = "Binned Age", x = "Axis1", y = "Axis2")

```
Pour ameiliorer notre compréhension du modèle random forests, on identifie la bactérie qui a le plus d'influence dans la prédiction. On peut voir apparaitre avec la premiere ligne de code que c'est Lachnospiraceae du genre Roseburia. Dans le graphique si dessous on va donc voir que cette batérie est très peu abondante chez les souris les plus jeunes, mais par contre elle aura une abondance plus importante chez les souris plus agées.
```{r}
as.vector(tax_table(ps)[which.max(importance(rfFit$finalModel)), c("Family", "Genus")])
```

```{r}
impOtu <- as.vector(otu_table(pslog)[,which.max(importance(rfFit$finalModel))])
maxImpDF <- data.frame(sample_data(pslog), abund = impOtu)
ggplot(maxImpDF) +   geom_histogram(aes(x = abund)) +
  facet_grid(age2 ~ .) +
  labs(x = "Abundance of discriminative bacteria", y = "Number of samples")
```
# Graph-based analyses
## Creating and plotting graphs
Nous pouvons créer, grâce à phyloseq, une matrice de distance basée sur le seuil. Le réseau en résultant peut etre visualisé grâce au package "ggnetwork".  Grâce aux fonction ggplot et igraph, nous pouvons organiser l'analyse en reseau. On va pouvoir également ajouter des couleurs selon nos noeuds grâce à igraph. Dans notre cas, nous choisissons de baser le seuil sur l'indice de dissimilarité de jaccard, en prenant une valeur seuil de 0,35. On ajoute ensuite dans indications pour savoir de quelle souris provient l'echantillon. A la fin nous obtenons une analyse en reseau colorée en fonction de la provenance de l'echantillon (= sur quelle souris il a été prélevé) et en fonction de la litière utilisée (1 ou2). 
ON peut voir sur l'analyse en reseau obtenue qu'on va avoir un regroupement des échantillons qui va former un noeud central assez dense, composé des échantillons des femelles 7 et males 1 et 2 majoritairement élevées sur la litière 1. GLobalement les litières forment des liaisons distinctes : les souris élevées sur la litière 1 seront plutôt regroupées ensembles et idem pour la litière 2. idem, les mâles auront tendance à être liés ensemble et les femelles ensembles aussi. On va donc ici pouvoir mettre en évidence que non seulement l'âge à un impact sur la communauté microbienne, mais aussi la parenté entre les individus et le sexe de ceux ci.

```{r}
library("phyloseqGraphTest")
library("igraph")
library("ggnetwork")
net <- make_network(ps, max.dist=0.35)
sampledata <- data.frame(sample_data(ps))
V(net)$id <- sampledata[names(V(net)), "host_subject_id"]
V(net)$litter <- sampledata[names(V(net)), "family_relationship"]
net_graph<-ggnetwork(net)
ggplot(net_graph, aes(x = x, y = y, xend = xend, yend = yend), layout = "fruchtermanreingold") +
  geom_edges(color = "darkgray") +
  geom_nodes(aes(color = id, shape = litter),  size = 3 ) +
  theme(axis.text = element_blank(), axis.title = element_blank(),
        legend.key.height = unit(0.5,"line")) +
  guides(col = guide_legend(override.aes = list(size = .5)))
```
## Minimum Spanning Tree (MST)
Cette méthode d'analyse est basée sur les distances entre les échantillons, puis sur le dénombrement des bouts des branches qu'il y a entre ces échantillons dans les différents groupes. Pour modéliser l'arbre, cette méthode utilise les "nearest neighbors" ou une distance seuil établie. Ce qui compte à la fin c'est les noeuds finaux retouvés au bout des branches, et non l'arbre intermédiaire. Celui-ci sera changé en fonction de l'ordre des échantillons, mais comme la méthode est fiable, les bouts des branches avec les distances finales demeureront inchangés. 
Dans notre premier code pour faire cet arbre nous utilisons l'indice de dissimilarité de Jaccard. Cet arbre aura pour but de verifier qu'au sein des mêmes portées nous retrouvons une distribution des abondances similaires. Ceci est traduit par l'argument "family_relationship". Par contre ici nous allons avoir besoin de maintenir ces structures imbriquées, nous ne pouvons pas les permuter simplement. C'est ce que fait l'argument "grouping". On va pouvoir faire ainsi des permutations mais en gardant cette structure intacte.

```{r}
gt <- graph_perm_test(ps, "family_relationship", grouping = "host_subject_id",
                      distance = "jaccard", type = "mst")
gt$pval
```
On retrouve une faible p-value dans ce test où nous rejettons l'hypothèse nulle que les deux échantillons (et donc lignées) proviennent d'une même distribution. On peut voir grâce a notre figure que les échantillons sont beaucoup plus groupés par portée que ce qu'on aurait pu obtenir par hasard.
```{r}
plotNet1=plot_test_network(gt) + theme(legend.text = element_text(size = 8),
        legend.title = element_text(size = 9))
plotPerm1=plot_permutations(gt)
grid.arrange(ncol = 2,  plotNet1, plotPerm1)
```
## Nearest neighbors
Le graphique des voisins les plus proches permet de séparer les deux portées qui ne se retrouvent jamais mélangées l'une avec l'autre. Ainsi, lorsque deux points sont proches entre eux, on aura une forte probabilité qu'il appartiennent à la même lignée.
```{r}
gt <- graph_perm_test(ps, "family_relationship", grouping = "host_subject_id",
                      distance = "jaccard", type = "knn", knn = 1)
plotNet2=plot_test_network(gt) + theme(legend.text = element_text(size = 8),
        legend.title = element_text(size = 9))
plotPerm2=plot_permutations(gt)
grid.arrange(ncol = 1,  plotNet2, plotPerm2)
```


## Linear modeling
### Modèle mixte
Pouvoir évaluer l'impacte de l'environnement dans lesquels les echantillons ont été prélevés est un autre moyen d'analyser des données. Ici on veut décrire comment une seule mesure par rapport à toutes les données peut être associée aux caractéristiques de l'échantillon. On va donc pouvoir obtenir cela grâce à la modelisation linéaire. Ici nous allons étudier cela en utilisant un modèle mixte. C'est un modèle qui utilise des effets fixes et aléatoires, ce qui permet de passer outre certaines mesures manquantes. Nous allons l'utiliser pour etudier la relation entre la diversité du microbiome d'une souris avec les variables d'âge et de portée qu'on a deja pu étudier au travers des autres analyses plus haut.
Ce type d'étude sera pertinante car nous avons déjà pu observer que les souris jeunes avaient une diversité bien plus faible selon l'indice de Shannon. Les données obtenues vont nous permettre de visualiser tout ça. 
On commence donc à associer l'indice de diversité de Shannon avec chaque échantillon pour les joindre avec les annotations des échantillons.
On peut voir apparaitre ici clairement pour chaque souris, mâle ou femelle, la diversité de Shannon, en fonction de la portée dont elle provient.
```{r}
library("nlme")
library("reshape2")
ps_alpha_div <- estimate_richness(ps, split = TRUE, measure = "Shannon")
ps_alpha_div$SampleID <- rownames(ps_alpha_div) %>%
  as.factor()
ps_samp <- sample_data(ps) %>%
  unclass() %>%
  data.frame() %>%
  left_join(ps_alpha_div, by = "SampleID") %>%
  melt(measure.vars = "Shannon",
       variable.name = "diversity_measure",
       value.name = "alpha_diversity")

# reorder's facet from lowest to highest diversity
diversity_means <- ps_samp %>%
  group_by(host_subject_id) %>%
  summarise(mean_div = mean(alpha_diversity)) %>%
  arrange(mean_div)
ps_samp$host_subject_id <- factor(ps_samp$host_subject_id)
#                                  diversity_means$host_subject_id)
alpha_div_model <- lme(fixed = alpha_diversity ~ age_binned, data = ps_samp,
                       random = ~ 1 | host_subject_id)
new_data <- expand.grid(host_subject_id = levels(ps_samp$host_subject_id),
                        age_binned = levels(ps_samp$age_binned))
new_data$pred <- predict(alpha_div_model, newdata = new_data)
X <- model.matrix(eval(eval(alpha_div_model$call$fixed)[-2]),
                  new_data[-ncol(new_data)])
pred_var_fixed <- diag(X %*% alpha_div_model$varFix %*% t(X))
new_data$pred_var <- pred_var_fixed + alpha_div_model$sigma ^ 2
# fitted values, with error bars
ggplot(ps_samp %>% left_join(new_data)) +
  geom_errorbar(aes(x = age_binned, ymin = pred - 2 * sqrt(pred_var),
                    ymax = pred + 2 * sqrt(pred_var)),
                col = "#858585", size = .1) +
  geom_point(aes(x = age_binned, y = alpha_diversity,
                 col = family_relationship), size = 0.8) +
  facet_wrap(~host_subject_id) +
  scale_y_continuous(limits = c(2.4, 4.6), breaks = seq(0, 5, .5)) +
  scale_color_brewer(palette = "Set2") +
  labs(x = "Binned Age", y = "Shannon Diversity", color = "Litter") +
  guides(col = guide_legend(override.aes = list(size = 4))) +
  theme(panel.border = element_rect(color = "#787878", fill = alpha("white", 0)),
        axis.text.x = element_text(angle = -90, size = 6),
        axis.text.y = element_text(size = 6))

ps_alpha_div <- estimate_richness(ps, split = TRUE, measure = "Shannon")
ps_alpha_div$SampleID <- rownames(ps_alpha_div) %>%
  as.factor()
ps_samp <- sample_data(ps) %>%
  unclass() %>%
  data.frame() %>%
  left_join(ps_alpha_div, by = "SampleID") %>%
  melt(measure.vars = "Shannon",
       variable.name = "diversity_measure",
       value.name = "alpha_diversity")
```
#Hierarchical multiple testing
Hypothesis testing can be used to identify individual microbes whose abundance relates to sample variables of interest. A standard approach is to compute a test statistic for each bacteria individually, measuring its association with sample characteristics, and then jointly adjust p-values to ensure a False Discovery Rate upper bound. This can be accomplished through the Benjamini-Hochberg procedure, for example (Benjamini and Hochberg 1995). However, this procedure does not exploit any structure among the tested hypotheses – for example, it is likely that if one Ruminococcus species is strongly associated with age, then others are as well. To integrate this information, (Benjamini and Yekutieli 2003; Benjamini and Bogomolov 2014) proposed a hierarchical testing procedure, where taxonomic groups are only tested if higher levels are found to be be associated. In the case where many related species have a slight signal, this pooling of information can increase power.

We apply this method to test the association between microbial abundance and age. This provides a complementary view of the earlier analyses, identifying individual bacteria that are responsible for the differences between young and old mice.

We digress briefly from hierarchical testing to describe an alternative form of count normalization. Rather than working with the logged data as in our earlier analysis, we consider a variance stabilizing transformation introduced by (Love, Huber, and Anders 2014) for RNA-seq data and in (McMurdie and Holmes 2014) for 16S rRNA generated count data and available in the DESeq2 package. The two transformations yield similar sets of significant microbes. One difference is that, after accounting for size factors, the histogram of row sums for DESeq is more spread out in the lower values, refer to Figure 23. This is the motivation of using such a transformation, although for high abundance counts, it is equivalent to the log, for lower and mid range abundances it does not crush the data and yields more powerful results. The code below illustrates the mechanics of computing ’s variance stabilizing transformation on a object.

```{r}
library("reshape2")
library("DESeq2")
#New version of DESeq2 needs special levels
sample_data(ps)$age_binned <- cut(sample_data(ps)$age,
                          breaks = c(0, 100, 200, 400))
levels(sample_data(ps)$age_binned) <- list(Young100="(0,100]", Mid100to200="(100,200]", Old200="(200,400]")
sample_data(ps)$family_relationship = gsub(" ", "", sample_data(ps)$family_relationship)
ps_dds <- phyloseq_to_deseq2(ps, design = ~ age_binned + family_relationship)

# geometric mean, set to zero when all coordinates are zero
geo_mean_protected <- function(x) {
  if (all(x == 0)) {
    return (0)
  }
  exp(mean(log(x[x != 0])))
}

geoMeans <- apply(counts(ps_dds), 1, geo_mean_protected)
ps_dds <- estimateSizeFactors(ps_dds, geoMeans = geoMeans)
ps_dds <- estimateDispersions(ps_dds)
abund <- getVarianceStabilizedData(ps_dds)
```

```{r}
short_names <- substr(rownames(abund), 1, 5)%>%
  make.names(unique = TRUE)
rownames(abund) <- short_names
```

```{r}
abund_sums <- rbind(data.frame(sum = colSums(abund),
                               sample = colnames(abund),
                               type = "DESeq2"),
                    data.frame(sum = rowSums(otu_table(pslog)),
                               sample = rownames(otu_table(pslog)),
                               type = "log(1 + x)"))

ggplot(abund_sums) +
  geom_histogram(aes(x = sum), binwidth = 20) +
  facet_grid(type ~ .) +
  xlab("Total abundance within sample")
```

```{r}
library("structSSI")
el <- phy_tree(pslog)$edge
el0 <- el
el0 <- el0[nrow(el):1, ]
el_names <- c(short_names, seq_len(phy_tree(pslog)$Nnode))
el[, 1] <- el_names[el0[, 1]]
el[, 2] <- el_names[as.numeric(el0[, 2])]
unadj_p <- treePValues(el, abund, sample_data(pslog)$age_binned)
```

```{r}
hfdr_res <- hFDR.adjust(unadj_p, el, .75)
summary(hfdr_res)
```

```{r}
#interactive part: not run
plot(hfdr_res, height = 5000) # opens in a browser
```

#retrieve the taxonomic identity of the rejected hypotheses.
```{r}
library(dplyr)
library (phyloseq)
library (dada2)
```

```{r}
tax <- tax_table(pslog)[, c("Family", "Genus")] %>%
  data.frame()
tax$seq <- short_names
```

```{r}
options(digits=3)
hfdr_res@p.vals$seq <- rownames(hfdr_res@p.vals)
tax %>%
  left_join(hfdr_res@p.vals) %>%
  arrange(adjp) %>% head(10)
```
#Multitable techniques
##Canonical Correlation Analysis
```{r}
metab <- read.csv("https://raw.githubusercontent.com/spholmes/F1000_workflow/master/data/metabolites.csv",row.names = 1)
microbe_connect <-url("https://raw.githubusercontent.com/spholmes/F1000_workflow/master/data/microbe.rda")
load(microbe_connect)
microbe
```
##filter down to microbes and metabolites of interest, removing those that are zero across many samples
```{r}
library("genefilter")
keep_ix <- rowSums(metab == 0) <= 3
metab <- metab[keep_ix, ]
microbe <- prune_taxa(taxa_sums(microbe) > 4, microbe)
microbe <- filter_taxa(microbe, filterfun(kOverA(3, 2)), TRUE)
metab <- log(1 + metab, base = 10)
X <- otu_table(microbe)
X[X > 50] <- 50
dim(X)
```
##the log of the metabolites
```{r}
dim(metab)
```
##The parameters penaltyx and penaltyz are sparsity penalties. Smaller values of penaltyx will result in fewer selected microbes, similarly penaltyz modulates the number of selected metabolites
```{r}
library(PMA)
cca_res <- CCA(t(X),  t(metab), penaltyx = .15, penaltyz = .15)
```

```{r}
cca_res
```
##To relate the recovered metabolites and OTUs to characteristics of the samples on which they were measured, we use them as input to an ordinary PCA
```{r}
library(ade4)
```

```{r}
combined <- cbind(t(X[cca_res$u != 0, ]),
                  t(metab[cca_res$v != 0, ]))
pca_res <- dudi.pca(combined, scannf = F, nf = 3)
```

```{r}
genotype <- substr(rownames(pca_res$li), 1, 2)
sample_type <- substr(rownames(pca_res$l1), 3, 4)
feature_type <- grepl("\\.", colnames(combined))
feature_type <- ifelse(feature_type, "Metabolite", "OTU")
sample_info <- data.frame(pca_res$li, genotype, sample_type)
feature_info <- data.frame(pca_res$c1,
                           feature = substr(colnames(combined), 1, 6))
```

```{r}
library(dplyr)
library(ggplot2)
library(ggrepel)
```

```{r}
ggplot() +  geom_point(data = sample_info,
            aes(x = Axis1, y = Axis2, col = sample_type, shape = genotype), size = 3) + 
  geom_label_repel(data = feature_info,
                   aes(x = 5.5 * CS1, y = 5.5 * CS2, label = feature, fill = feature_type),
                   size = 2, segment.size = 0.3,
                   label.padding = unit(0.1, "lines"), label.size = 0) +
  geom_point(data = feature_info,
             aes(x = 5.5 * CS1, y = 5.5 * CS2, fill = feature_type),
             size = 1, shape = 23, col = "#383838") +
  scale_color_brewer(palette = "Set2") +
  scale_fill_manual(values = c("#a6d854", "#e78ac3")) +
  guides(fill = guide_legend(override.aes = list(shape = 32, size = 0))) +
  coord_fixed(sqrt(pca_res$eig[2] / pca_res$eig[2])) +
  labs(x = sprintf("Axis1 [%s%% Variance]",
                   100 * round(pca_res$eig[1] / sum(pca_res$eig), 2)),
       y = sprintf("Axis2 [%s%% Variance]",
                   100 * round(pca_res$eig[2] / sum(pca_res$eig), 2)),
       fill = "Feature Type", col = "Sample Type")
```














